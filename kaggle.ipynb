{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading (only using 10000 entries for testing purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet = pd.read_csv(\"./data/train.csv\")\n",
    "testingSet = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "predictionSet = pd.merge(trainingSet, testingSet, left_on='Id', right_on='Id')\n",
    "print(predictionSet.columns)\n",
    "\n",
    "predictionSet = predictionSet.drop(columns=['Score_x'])\n",
    "predictionSet = predictionSet.rename(columns={'Score_y': 'Score'})\n",
    "\n",
    "print(predictionSet.columns)\n",
    "predictionSet.to_csv(\"./data/prediction.csv\", index=False)\n",
    "\n",
    "X_train = trainingSet[trainingSet['Score'].notnull()]\n",
    "print(trainingSet.shape)\n",
    "print(X_train.shape)\n",
    "X_train.to_csv(\"./data/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 9)\n",
      "(10000, 9)\n",
      "   Id   ProductId          UserId  HelpfulnessNumerator  \\\n",
      "0   0  0005019281   ADZPIG9QOCDG5                     0   \n",
      "1   1  0005019281  A35947ZP82G7JH                     0   \n",
      "2   2  0005019281  A3UORV8A9D5L2E                     0   \n",
      "3   3  0005019281  A1VKW06X1O2X7V                     0   \n",
      "4   4  0005019281  A3R27T4HADWFFJ                     0   \n",
      "\n",
      "   HelpfulnessDenominator  Score        Time  \\\n",
      "0                       0    4.0  1203984000   \n",
      "1                       0    3.0  1388361600   \n",
      "2                       0    3.0  1388361600   \n",
      "3                       0    5.0  1202860800   \n",
      "4                       0    4.0  1387670400   \n",
      "\n",
      "                                        Summary  \\\n",
      "0                     good version of a classic   \n",
      "1                        Good but not as moving   \n",
      "2         Winkler's Performance was ok at best!   \n",
      "3  It's an enjoyable twist on the classic story   \n",
      "4                              Best Scrooge yet   \n",
      "\n",
      "                                                Text  \n",
      "0  This is a charming version of the classic Dick...  \n",
      "1  It was good but not as emotionally moving as t...  \n",
      "2  Don't get me wrong, Winkler is a wonderful cha...  \n",
      "3  Henry Winkler is very good in this twist on th...  \n",
      "4  This is one of the best Scrooge movies out.  H...  \n",
      "   Id   ProductId          UserId  HelpfulnessNumerator  \\\n",
      "0   5  0005019281  A2L0G56BNOTX6S                     0   \n",
      "1  11  0005019281  A33EWPXESP9GQH                     0   \n",
      "2  17  0005019281  A13KAQO9F5X0FN                     0   \n",
      "3  46  0005019281  A306NASGVUDFKF                    10   \n",
      "4  47  0005019281  A38G1NN5SD81GD                     0   \n",
      "\n",
      "   HelpfulnessDenominator        Time  \\\n",
      "0                       0  1383696000   \n",
      "1                       0  1390780800   \n",
      "2                       0  1389657600   \n",
      "3                      14  1132963200   \n",
      "4                       1  1384905600   \n",
      "\n",
      "                                   Summary  \\\n",
      "0                         Dickens updated.   \n",
      "1                             Good Version   \n",
      "2                    the fonz does scrooge   \n",
      "3  A refreshing twist on a Holiday classic   \n",
      "4                          Not my favorite   \n",
      "\n",
      "                                                Text  Score  \n",
      "0  This has been a favorite movie of mine for a l...    NaN  \n",
      "1  Even though i don't care for Henry Winklers  a...    NaN  \n",
      "2  Anorher good movie for holiday watchers..a lit...    NaN  \n",
      "3  My wife and I grew up in New Hampshire where t...    NaN  \n",
      "4  This is a first for me, I didn't like this mov...    NaN  \n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./data/X_train.csv\").head(10000)\n",
    "pred_data = pd.read_csv(\"./data/prediction.csv\").head(10000)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(pred_data.shape)\n",
    "print(train_data.head())\n",
    "print(pred_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def remove_punc(text):         \n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def clean_helper(text):\n",
    "    return \" \".join([stemmer.stem(remove_punc(w)).lower() for w in text if w.lower() not in stop_words]).strip()\n",
    "\n",
    "#the main data cleaning function\n",
    "def data_cleaning(df):\n",
    "    df = df.apply(word_tokenize)\n",
    "    df = df.apply(clean_helper)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only care about the 'Text' and 'Summary' columns\n",
    "\n",
    "\n",
    "#replace Nan with empty spaces\n",
    "train_data['Text'].fillna('', inplace=True) \n",
    "train_data['Summary'].fillna('', inplace=True) \n",
    "\n",
    "\n",
    "# make sure there is space in between when combining 'Summary' and 'Text'\n",
    "train_data['Summary'] = train_data['Summary'].apply(lambda x: x+\" \") \n",
    "\n",
    "\n",
    "X_data = train_data['Summary'] + train_data['Text'] #text\n",
    "Y_data = train_data['Score'] #labels\n",
    "\n",
    "X_data_cleaned = data_cleaning(X_data)# remove puncs, stop words, lower case, stemming, and etc.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data_cleaned, Y_data, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#I use TfidfVectorizer as text vectorizer\n",
    "vec = TfidfVectorizer(sublinear_tf=True, min_df=2, max_df=0.9 , ngram_range=(1,3))\n",
    "\n",
    "X_train = vec.fit_transform(X_train)\n",
    "X_test = vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8755\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(class_weight=\"balanced\")# class_weight deals with imbalance data set\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_pred))# use mean square error as evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the model to predict our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data['Text'].fillna('', inplace=True)\n",
    "pred_data['Summary'].fillna('', inplace=True)\n",
    "pred_data['Summary'] = pred_data['Summary'].apply(lambda x: x+\" \")\n",
    "x_predict = pred_data['Summary'] + pred_data['Text']\n",
    "y_predict = pred_data['Score']\n",
    "\n",
    "\n",
    "x_predict_cleaned = data_cleaning(x_predict)\n",
    "\n",
    "x_predict_cleaned = vec.transform(x_predict_cleaned)\n",
    "result = svc.predict(x_predict_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Score\n",
      "0   5    5.0\n",
      "1  11    3.0\n",
      "2  17    4.0\n",
      "3  46    5.0\n",
      "4  47    5.0\n"
     ]
    }
   ],
   "source": [
    "pred_data['Score'] = result\n",
    "submission = pred_data[['Id', 'Score']]\n",
    "print(submission.head())\n",
    "#submission.to_csv(\"./data/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
